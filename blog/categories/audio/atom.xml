<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Audio | 码农人生]]></title>
  <link href="http://msching.github.io/blog/categories/audio/atom.xml" rel="self"/>
  <link href="http://msching.github.io/"/>
  <updated>2014-07-08T13:55:39+08:00</updated>
  <id>http://msching.github.io/</id>
  <author>
    <name><![CDATA[ChengYinZju]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[iOS音频播放 (一)：概述]]></title>
    <link href="http://msching.github.io/blog/2014/07/07/audio-in-ios/"/>
    <updated>2014-07-07T14:40:42+08:00</updated>
    <id>http://msching.github.io/blog/2014/07/07/audio-in-ios</id>
    <content type="html"><![CDATA[<h1>前言</h1>

<p>从事音乐相关的app开发也已经有一段时日了，在这过程中app的播放器几经修改我也因此对于iOS下的音频播放实现有了一定的研究。写这个系列的博客目的一方面希望能够抛砖引玉，另一方面也是希望能帮助国内其他的iOS开发者和爱好者少走弯路（我自己就遇到了不少的坑=。=）。</p>

<p>本篇为《iOS音频播放》系列的第一篇，主要将对iOS下实现音频播放的方法进行概述。</p>

<hr />

<h1>基础</h1>

<p>先来简单了解一下一些基础的音频知识。</p>

<p>目前我们在计算机上进行音频播放都需要依赖于音频文件，音频文件的生成过程是将声音信息采样、量化和编码产生的数字信号的过程，人耳所能听到的声音，最低的频率是从20Hz起一直到最高频率20KHZ，因此音频文件格式的最大带宽是20KHZ。根据<a href="http://zh.wikipedia.org/wiki/%E5%A5%88%E5%A5%8E%E6%96%AF%E7%89%B9%E9%A2%91%E7%8E%87">奈奎斯特</a>的理论，只有采样频率高于声音信号最高频率的两倍时，才能把数字信号表示的声音还原成为原来的声音，所以音频文件的采样率一般在40~50KHZ，比如最常见的CD音质采样率44.1KHZ。</p>

<p>对声音进行采样、量化过程被称为<a href="http://zh.wikipedia.org/wiki/%E8%84%88%E8%A1%9D%E7%B7%A8%E8%99%9F%E8%AA%BF%E8%AE%8A">脉冲编码调制</a>（Pulse Code Modulation），简称<code>PCM</code>。PCM数据是最原始的音频数据完全无损，所以PCM数据虽然音质优秀但体积庞大，为了解决这个问题先后诞生了一系列的音频格式，这些音频格式运用不同的方法对音频数据进行压缩，其中有无损压缩（ALAC、APE、FLAC）和有损压缩（MP3、AAC、OGG、WMA）两种。</p>

<p>目前最为常用的音频格式是MP3，MP3是一种有损压缩的音频格式，设计这种格式的目的就是为了大幅度的减小音频的数据量，它舍弃PCM音频数据中人类听觉不敏感的部分，从下面的比较图我们可以明显的看到MP3数据相比PCM数据明显矮了一截（图片引自<a href="http://bbs.imp3.net/thread-243641-1-1.html">imp3论坛</a>）。</p>

<p><img src="/images/iOS-audio/pcm.jpg" alt="上图为pcm数据" />
<img src="/images/iOS-audio/mp3.jpg" alt="上图为mp3数据" /></p>

<p>MP3格式中的码率（BitRate）代表了MP3数据的压缩质量，现在常用的码率有128kbit/s、160kbit/s、320kbit/s等等，这个值越高声音质量也就越高。MP3编码方式常用的有两种<a href="http://zh.wikipedia.org/wiki/%E5%9B%BA%E5%AE%9A%E7%A0%81%E7%8E%87">固定码率</a>(Constant bitrate，CBR)和<a href="http://zh.wikipedia.org/wiki/%E5%8F%AF%E5%8F%98%E7%A0%81%E7%8E%87">可变码率</a>(Variable bitrate，VBR)。</p>

<p>MP3格式中的数据通常由两部分组成，一部分为<a href="http://zh.wikipedia.org/zh/ID3">ID3</a>用来存储歌名、演唱者、专辑、音轨数等信息，另一部分为音频数据。音频数据部分以帧(frame)为单位存储，每个音频都有自己的帧头，如图所示就是一个MP3文件帧结构图（图片同样来自互联网）。MP3中的每一个帧都有自己的帧头，其中存储了码率、采样率等解码必须的信息，所以每一个帧都可以独立于文件存在和播放，这个特性加上高压缩比使得MP3文件成为了音频流播放的主流格式。</p>

<p><img src="/images/iOS-audio/mp3frame.jpg" alt="" /></p>

<hr />

<h1>iOS音频播放概述</h1>

<p>了解了基础概念之后我们就可以列出一个经典的音频播放流程（以MP3为例）：</p>

<ol>
<li>读取MP3文件</li>
<li>分离MP3中的音频帧</li>
<li>对分离出来的音频帧解码得到PCM数据</li>
<li>对PCM数据进行音效处理（均衡器、混响器等，非必须）</li>
<li>把PCM数据解码成音频信号</li>
<li>把音频信号交给硬件播放</li>
<li>重复1-6步直到播放完成</li>
</ol>


<p>在iOS系统中apple对上述的流程进行了封装并提供了不同层次的接口（图片引自<a href="https://developer.apple.com/library/ios/documentation/MusicAudio/Conceptual/CoreAudioOverview/CoreAudioEssentials/CoreAudioEssentials.html#//apple_ref/doc/uid/TP40003577-CH10-SW1">官方文档</a>）。</p>

<p><img src="/images/iOS-audio/api-architectural-layers.png" alt="CoreAudio的接口层次" /></p>

<p>下面对其中的中高层接口进行功能说明：</p>

<ul>
<li>Audio File Services：读写音频数据，可以完成播放流程中的第1、2步；</li>
<li>Audio File Stream Services：对音频进行解码，可以完成播放流程中的第2部；</li>
<li>Audio Converter services：音频数据转换，可以完成播放流程中的第3步；</li>
<li>Audio Processing Graph Services：音效处理模块，可以完成播放流程中的第4步；</li>
<li>Audio Unit Services：播放音频数据：可以完成播放流程中的第5步、第6步；</li>
<li>Extended Audio File Services：Audio File Services和Audio Converter services的结合体；</li>
<li>AVAudioPlayer/AVPlayer(AVFoundation)：高级接口，可以完成整个音频播放的过程（包括本地文件和网络流播放，第4步除外）；</li>
<li>Audio Queue Services：高级接口，可以进行录音和播放，可以完成播放流程中的第3、5、6步；</li>
<li>OpenAL：用于游戏音频播放，暂不讨论</li>
</ul>


<p>可以看到apple提供的接口类型非常丰富，可以满足各种类别类需求：</p>

<ul>
<li><p>如果你只是想实现音频的播放，没有其他需求AVFoundation会很好的满足你的需求。它的接口使用简单、不用关心其中的细节；</p></li>
<li><p>如果你的app需要对音频进行流播放并且同时存储，那么AudioFileStreamer加AudioQueue能够帮到你，你可以把音频数据下载到本地，用NSFileHandler读取本地音频文件并交给AudioFileStreamer分离音频帧，分离出来的音频帧可以送给AudioQueue进行解码和播放。如果是本地文件也可以直接用AudioFile读取文件并分离帧。（这两个都是比较直接的做法，这类需求也可以用AVFoundation+本地server的方式实现，AVAudioPlayer会把请求发送给本地server，由本地server转发出去，获取数据后在本地server中存储并转送给AVAudioPlayer。另一个比较trick的做法是先把音频下载到文件中，在下载到一定量的数据后把文件路径给AVAudioPlayer播放，当然这种做法在音频seek后就回有问题了。）；</p></li>
<li><p>如果你正在开发一个专业的音乐播放软件，需要对音频施加音效（均衡器、混响器），那么除了数据的读取以外还需要用到AudioConverter来把音频数据转换成PCM数据，再由AudioUnit+AUGraph来进行音效处理和播放（但目前多数带音效的app都是自己开发音效模块来坐PCM数据的处理，这部分功能自行开发在自定义性和扩展性上会比较强一些。PCM数据通过音效器处理完成后就可以使用AudioUnit播放了，当然AudioQueue也支持直接使对PCM数据进行播放。）。下图描述的就是使用AudioFile + AudioConverter + AudioUnit进行音频播放的流程（图片引自<a href="https://developer.apple.com/library/ios/documentation/MusicAudio/Conceptual/CoreAudioOverview/ARoadmaptoCommonTasks/ARoadmaptoCommonTasks.html#//apple_ref/doc/uid/TP40003577-CH6-SW1">官方文档</a>）。</p></li>
</ul>


<p><img src="/images/iOS-audio/audioUnitPlay.jpg" alt="" /></p>

<hr />

<h1>下篇预告</h1>

<p>下一篇将讲述iOS音频播放中必须面对的难（da）题（keng），AudioSession。</p>

<hr />

<h1>参考资料</h1>

<p><a href="http://zh.wikipedia.org/zh/%E9%9F%B3%E9%A2%91%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F">音频文件格式</a></p>

<p><a href="http://zh.wikipedia.org/wiki/%E8%84%88%E8%A1%9D%E7%B7%A8%E8%99%9F%E8%AA%BF%E8%AE%8A">脉冲编码调制</a></p>

<p><a href="http://zh.wikipedia.org/zh/%E9%87%87%E6%A0%B7%E7%8E%87">采样率</a></p>

<p><a href="http://zh.wikipedia.org/wiki/%E5%A5%88%E5%A5%8E%E6%96%AF%E7%89%B9%E9%A2%91%E7%8E%87">奈奎斯特频率</a></p>

<p><a href="http://zh.wikipedia.org/wiki/MP3">MP3</a></p>

<p><a href="http://zh.wikipedia.org/zh/ID3">ID3</a></p>

<p><a href="https://developer.apple.com/library/ios/documentation/MusicAudio/Conceptual/CoreAudioOverview/CoreAudioEssentials/CoreAudioEssentials.html#//apple_ref/doc/uid/TP40003577-CH10-SW1">Core Audio Essential</a></p>

<p><a href="https://developer.apple.com/library/ios/documentation/MusicAudio/Conceptual/CoreAudioOverview/ARoadmaptoCommonTasks/ARoadmaptoCommonTasks.html#//apple_ref/doc/uid/TP40003577-CH6-SW1">Common Tasks in OS X</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iOS8beta1下WebCore可能会打断音频播放]]></title>
    <link href="http://msching.github.io/blog/2014/06/26/audio-interrput-by-webcore-in-ios-8-beta-1/"/>
    <updated>2014-06-26T16:09:56+08:00</updated>
    <id>http://msching.github.io/blog/2014/06/26/audio-interrput-by-webcore-in-ios-8-beta-1</id>
    <content type="html"><![CDATA[<h1>问题</h1>

<p>前不久在QA发现一个问题，在iOS8 beta1上使用我们的app播放歌曲时进入某些内嵌的web页面（UIWebview实现）时歌曲会暂停播放，但是界面仍然显示为正在播放状态。把真机连上Xcode6调试后发现在进入部分网页时会再console上打印如下log：</p>

<pre><code>AVAudioSession.mm:623: -[AVAudioSession setActive:withOptions:error:]: Deactivating an audio session that has running I/O. All I/O should be stopped or paused prior to deactivating the audio session.
</code></pre>

<p>bt后堆栈如下：</p>

<p>```</p>

<pre><code>frame #1: 0x299632fe libAVFAudio.dylib`-[AVAudioSession setActive:error:] + 26
frame #2: 0x3551b92e WebCore`WebCore::AudioSession::setActive(bool) + 62
frame #3: 0x35af2674 WebCore`WebCore::MediaSessionManager::updateSessionState() + 100
frame #4: 0x35af03b6 WebCore`WebCore::MediaSessionManager::addSession(WebCore::MediaSession&amp;) + 74
frame #5: 0x35af0002 WebCore`WebCore::MediaSession::MediaSession(WebCore::MediaSessionClient&amp;) + 38
frame #6: 0x35735a20 WebCore`WebCore::HTMLMediaSession::create(WebCore::MediaSessionClient&amp;) + 20
frame #7: 0x35724c68 WebCore`WebCore::HTMLMediaElement::HTMLMediaElement(WebCore::QualifiedName const&amp;, WebCore::Document&amp;, bool) + 976
frame #8: 0x3570ad24 WebCore`WebCore::HTMLAudioElement::create(WebCore::QualifiedName const&amp;, WebCore::Document&amp;, bool) + 36
frame #9: 0x35718184 WebCore`WebCore::audioConstructor(WebCore::QualifiedName const&amp;, WebCore::Document&amp;, WebCore::HTMLFormElement*, bool) + 56
frame #10: 0x3571803a WebCore`WebCore::HTMLElementFactory::createElement(WebCore::QualifiedName const&amp;, WebCore::Document&amp;, WebCore::HTMLFormElement*, bool) + 230
frame #11: 0x3533a26c WebCore`WebCore::HTMLDocument::createElement(WTF::AtomicString const&amp;, int&amp;) + 88
frame #12: 0x3533a1ae WebCore`WebCore::jsDocumentPrototypeFunctionCreateElement(JSC::ExecState*) + 242
frame #13: 0x2c1cc4d4 JavaScriptCore`llint_entry + 21380
</code></pre>

<p>```</p>

<p>发现是WebCore调用了<code>AVAudioSession</code>的setActive方法，并且把active置为了NO。这个过程其实类似于音乐在播放时被其他事件打断（例如电话、siri）一样，audio会被打断，同时会发送<code>kAudioSessionBeginInterruption</code>事件通知app音频播放已经被打断，需要修正播放器和UI状态；打断结束后回发送<code>kAudioSessionEndInterruption</code>事件通知app恢复播放状态。区别在于WebCore的打断并没有任何通知，所以就导致界面上的播放状态为播放中而实际音乐却被打断。</p>

<h1>适配</h1>

<p>接下来就要对这个问题进行适配了：</p>

<ol>
<li>首先，联系了前段组的同事对出现问题的页面进行检查，之后被告知是某个页面的js中调用了一些播放相关的代码导致了这个问题，这些js是之前版本中使用的，现在已经被废弃但没有及时的删除。在删除这些js后，问题自然就消失了。</li>
<li>客户端本身也应该做一些适配来防止下次再有页面出现类似问题，目前我能想到的办法是做一个<code>AVAudioSession</code>的category，method swizzle方法<code>setActive:withOptions:error:</code>在设置active值时发送通知来修改UI的状态。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[初始化AudioUnit的正确姿势]]></title>
    <link href="http://msching.github.io/blog/2014/06/25/init-audiounit-when-app-is-in-background/"/>
    <updated>2014-06-25T13:56:27+08:00</updated>
    <id>http://msching.github.io/blog/2014/06/25/init-audiounit-when-app-is-in-background</id>
    <content type="html"><![CDATA[<p>在使用AudioUnit的过程中发现当app在后台时调用<code>extern OSStatus AudioUnitInitialize(AudioUnit inUnit)</code>方法返回<code>561015905</code>错误码，解析成string后是<code>!pla</code>，google错误码后毫无收获，于是只能workaround。面对这个问题我的workaround是当出现初始化失败的情况下会在程序进入前台时再尝试调用<code>AudioUnitInitialize</code>方法来初始化AudioUnit。至此问题已经在一定程度上得到了解决，只要用户进入前台就可以正确初始化AudioUnit并且播放音乐。</p>

<p>今天在应对某个用户反馈时发现该用户在使用remoteControl过程中无法启动播放的情况正是因为后台init AudioUnit会失败导致程序无法如预期工作。于是灵光一闪，觉得在初始化AudioUnit之前先调用<code>AudioSessionInitialize</code>并setActive是否就可以解决问题。尝试之后发现果然可以&hellip;（之前都在AudioUnitInitialize成功后才去init audiosession）。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AVAudioPlayer的1937337955错误研究]]></title>
    <link href="http://msching.github.io/blog/2014/05/04/secret-of-avaudioplayer/"/>
    <updated>2014-05-04T19:46:53+08:00</updated>
    <id>http://msching.github.io/blog/2014/05/04/secret-of-avaudioplayer</id>
    <content type="html"><![CDATA[<h1>问题</h1>

<p>前两天公司有一位同事在使用AVAudioPlayer的过程中遇到了这样一个问题：</p>

<p>他需要播放一段网络上的音频，实现策略是把音频下载到本地，然后使用AVAudioPlayer进行播放。代码大致是这样的：</p>

<p><code>objective-c
NSString *path = .../xxx.mp3; //mp3 file path
NSData *data = [NSData dataWithContentsOfURL:[NSURL fileURLWithPath:path]];
NSError *error = nil;
AVAudioPlayer *player = [[AVAudioPlayer alloc] initWithData:data error:&amp;error];
</code></p>

<p>但他在init AVAudioPlayer时遇到了下面的错误。</p>

<p><code>objective-c
Error Domain=NSOSStatusErrorDomain Code=1937337955 "The operation couldn’t be completed. (OSStatus error 1937337955.)"
</code></p>

<hr />

<h1>普遍的解决方法</h1>

<p>在google搜索之后发现1937337955这个code并不少见，在<a href="http://stackoverflow.com/questions/4901709/iphone-avaudioplayer-unsupported-file-type">StackOverflow</a>上有人提问问到这个问题，国内的一些博客中也有提到（例如<a href="http://zhu340381425.blog.163.com/blog/static/75952514201192021013852">@我的桌子</a>和<a href="http://blog.sina.com.cn/s/blog_7cb9b3b80101d8ap.html">@SkyLine</a>）。</p>

<p>其中提到的解决方法都一样，就是使用AVAudioPlayer的另一个init方法：</p>

<p><code>objective-c
- (id)initWithContentsOfURL:(NSURL *)url error:(NSError **)outError;
</code>
于是尝试修改了代码：</p>

<p><code>objective-c
NSString *path = .../xxx.mp3; //mp3 file path
NSError *error = nil;
AVAudioPlayer *player = [[AVAudioPlayer alloc] initWithContentsOfURL:[NSURL fileURLWithPath:path] error:&amp;error];
</code>
果然没有出现错误，player成功创建并且能够播放。</p>

<hr />

<h1>深究</h1>

<p>不能播放的问题到这里已经fix了，但这个问题本身还没有完结，为什么使用<code>-initWithContentsOfURL:error:</code>方法就可以播呢？这个时候也许有的人会认为这是一个apple的bug，认为<code>-initWithContentsOfURL:error:</code>方法比<code>-initWithData::error:</code>具有更好的适应性。</p>

<pre><code>Oh that's very interesting. Perhaps that should be submitted to Apple as a bug? 
In the end I opted for the saved file anyways because it fit better with what we were trying to do. 
Thanks for the Tip! –  mtmurdock Mar 19 '11 at 0:26
</code></pre>

<p>但凡事遇到错误，都应该先从自身开始找原因。经过搜索发现，1937337955这个Errorcode其实就是<code>kAudioFileUnsupportedFileTypeError</code>，一般出现在文件格式不符合规范的情况下。假设apple并没有写出bug的话，那么上述问题中的这个mp3一定在文件格式上有缺陷，最终导致了<code>-initWithData::error:</code>方法返回错误，而<code>-initWithContentsOfURL:error:</code>采用某种方式规避了这个格式缺陷。</p>

<p>回过头去查看<code>AVAudioPlayer.h</code>头文件可以看到SDK7中多了两个init方法：</p>

<p><code>objective-c
/* The file type hint is a constant defined in AVMediaFormat.h whose value is a UTI for a file format. e.g. AVFileTypeAIFF. */
/* Sometimes the type of a file cannot be determined from the data, or it is actually corrupt.
The file type hint tells the parser what kind of data to look for so that files which are not self identifying or possibly even corrupt can be successfully parsed. */
- (id)initWithContentsOfURL:(NSURL *)url fileTypeHint:(NSString*)utiString error:(NSError **)outError NS_AVAILABLE(10_9, 7_0);
- (id)initWithData:(NSData *)data fileTypeHint:(NSString*)utiString error:(NSError **)outError NS_AVAILABLE(10_9, 7_0);
</code></p>

<p>多出来的这个hint参数和<code>AudioToolbox</code>framework中<code>AudioFileStream</code>、<code>AudioFile</code>两个类的Open方法中所使用的hint参数作用一样，可以辅助系统判定当前的文件格式。</p>

<p>接下来尝试在iOS7系统下使用新的init方法生成AVAudioPlayer：</p>

<p><code>objective-c
NSString *path = .../xxx.mp3; //mp3 file path
NSData *data = [NSData dataWithContentsOfURL:[NSURL fileURLWithPath:path]];
NSError *error = nil;
AVAudioPlayer *player = [[AVAudioPlayer alloc] initWithData:data fileTypeHint:AVFileTypeMPEGLayer3 error:&amp;error];
</code></p>

<p>结果没有错误产生，没有出现错误，player成功创建并且能够播放。</p>

<p>进而进行另两个实验：</p>

<ol>
<li>把保存文件时的.mp3后缀去掉后使用<code>-initWithContentsOfURL:error:</code>生成对象，结果发现产生了错误。</li>
<li>把保存文件时的.mp3后缀改为.wav后使用<code>-initWithContentsOfURL:error:</code>生成对象，结果发现产生了错误。</li>
</ol>


<p>于是确定<code>-initWithContentsOfURL:error:</code>方法是利用后缀名作为hintType对文件的解码进行辅助，而<code>-initWithData::error:</code>方法由于没有任何hint并且文件本身格式又有缺陷导致错误的产生。</p>

<hr />

<h1>更完整的解决方法</h1>

<p>基于以上分析可以得出一个更为完整的解决方法，可以有效的规避这一类错误：</p>

<ol>
<li>对于iOS7以上的系统（含iOS7）,在确定文件格式的情况下可以使用<code>initWithData:fileTypeHint:error:</code>和<code>initWithContentsOfURL:fileTypeHint:error:</code>生成实例，或者把data保存为对应后缀名的文件后使用<code>-initWithContentsOfURL:error:</code>后再生成实例；</li>
<li>对于iOS7以下的系统，在确定文件格式的情况下，最为安全的方法是把data保存为对应后缀名的文件后使用<code>-initWithContentsOfURL:error:</code>生成实例；</li>
</ol>


<p>如果上述方法帮不了你，那么就只能去检查文件格式有没有问题或者采用其他的实现方式进行尝试了（比如<code>AVPlayer</code>和<code>AudioToolBox</code>）。不管怎么说，客户端所能做的只是尽量减少错误发生的频率，最终解决这类问题还是需要音频文件的提供者确保音频文件的格式符合标准没有错误和缺陷。</p>
]]></content>
  </entry>
  
</feed>
